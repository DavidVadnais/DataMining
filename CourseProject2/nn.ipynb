{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8bc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from keras.layers import  Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d062ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(X_train, X_test,MAX_NB_WORDS=10000):\n",
    "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS)\n",
    "    X_train = vectorizer_x.fit_transform(X_train).toarray()\n",
    "    X_test  = vectorizer_x.transform(X_test).toarray()\n",
    "    return (X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99cb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='./20_newsgroups_Train'\n",
    "root_dirL = len(root_dir)+1\n",
    "# root_dir needs a trailing slash (i.e. /root/dir/)\n",
    "i = 0\n",
    "train = []#pd.DataFrame(columns=['folder', 'fileName'])\n",
    "for filename in glob.iglob(root_dir + '**/**/*', recursive=True):\n",
    "    if i > 19:\n",
    "        for j, c in enumerate(filename[root_dirL:]):\n",
    "            if c.isdigit():\n",
    "                bs = j\n",
    "                #print(bs)\n",
    "                break\n",
    "        #print(filename[22:])\n",
    "        #print(filename[22:22+bs-1])#lable\n",
    "        label = filename[root_dirL:root_dirL+bs-1]\n",
    "        #print(filename[22+bs:])#filename\n",
    "        filenametmp = filename[root_dirL+bs:]\n",
    "        train.append([label,filenametmp])\n",
    "    #print(filename)\n",
    "    i+=1\n",
    "    \n",
    "root_dirTest='./20_newsgroups_Test'\n",
    "root_dirTL = len(root_dirTest)+1\n",
    "# root_dir needs a trailing slash (i.e. /root/dir/)\n",
    "i = 0\n",
    "test = []#pd.DataFrame(columns=['folder', 'fileName'])\n",
    "for filename in glob.iglob(root_dirTest + '**/**/*', recursive=True):\n",
    "    if i > 19:\n",
    "        for j, c in enumerate(filename[root_dirTL:]):\n",
    "            if c.isdigit():\n",
    "                bs = j\n",
    "                #print(bs)\n",
    "                break\n",
    "        #print(filename[22:])\n",
    "        #print(filename[22:22+bs-1])#lable\n",
    "        label = filename[root_dirTL:root_dirTL+bs-1]\n",
    "        #print(filename[22+bs:])#filename\n",
    "        filenametmp = filename[root_dirTL+bs:]\n",
    "        test.append([label,filenametmp])\n",
    "    #print(filename)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df47aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocsAsStringsTrain=[]\n",
    "allDocsAsStringsNoLabelsTrain = []\n",
    "lastrow=\"\"\n",
    "\n",
    "category = -1\n",
    "ytest = []\n",
    "ytrain = []\n",
    "for row in train:\n",
    "    fileToOpen= root_dir+'/'+row[0]+'/'+row[1]\n",
    "    \n",
    "    file=open(fileToOpen,\"r\")\n",
    "    tmp = file.read().lower()#text_cleaner(file.read()).lower()\n",
    "    \n",
    "    if (row[0]!= lastrow):\n",
    "        lastrow = row[0]\n",
    "        category += 1\n",
    "    allDocsAsStringsTrain.append([row[0],row[1],tmp])\n",
    "    ytrain.append(category)\n",
    "    allDocsAsStringsNoLabelsTrain.append(tmp)\n",
    "    file.close()\n",
    "    \n",
    "allDocsAsStringsTest=[]\n",
    "allDocsAsStringsNoLabelsTest = []\n",
    "lastrow=\"\"\n",
    "category = -1\n",
    "for row in test:\n",
    "    fileToOpen= root_dirTest+'/'+row[0]+'/'+row[1]\n",
    "    if (row[0]!= lastrow):\n",
    "        lastrow = row[0]\n",
    "        category+=1\n",
    "    \n",
    "    #print(fileToOpen)\n",
    "    file=open(fileToOpen,\"r\")\n",
    "    tmp = file.read().lower()#text_cleaner(file.read()).lower()\n",
    "    ytest.append(category)\n",
    "    allDocsAsStringsTest.append([row[0],row[1],tmp])\n",
    "    allDocsAsStringsNoLabelsTest.append(tmp)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abef87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "i=0\n",
    "#ytrain = []\n",
    "for doc in allDocsAsStringsNoLabelsTrain:\n",
    "    corpus.append(''.join((element for element in doc if not (element.isdigit() or element =='_'))))\n",
    "    #if i%10 == 0:\n",
    "    #    print(doc)\n",
    "    #ytrain.append(allDocsAsStringsTrain[i][3])\n",
    "    i=+1\n",
    "    \n",
    "#ytest = []  \n",
    "corpusTest = []\n",
    "i=0\n",
    "for doc in allDocsAsStringsNoLabelsTest:\n",
    "    corpusTest.append(''.join((element for element in doc if not (element.isdigit() or element =='_'))))\n",
    "    #ytest.append(allDocsAsStringsTest[i][3])\n",
    "\n",
    "    i=+1\n",
    "ytrain=np.array(ytrain)\n",
    "ytest =np.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b40d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf,X_test_tfidf = TFIDF(corpus,corpusTest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c3c76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "node = 512 # number of nodes\n",
    "nLayers = 3 # number of  hidden layer\n",
    "dropout=0.5\n",
    "shape = X_train_tfidf.shape[1]\n",
    "nClasses = 20\n",
    "model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "for i in range(0,nLayers):\n",
    "    model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f55575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 - 3s - loss: 2.7713 - accuracy: 0.1235 - val_loss: 1.6881 - val_accuracy: 0.5003 - 3s/epoch - 49ms/step\n",
      "Epoch 2/10\n",
      "63/63 - 2s - loss: 1.0665 - accuracy: 0.6245 - val_loss: 0.4116 - val_accuracy: 0.8728 - 2s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "63/63 - 2s - loss: 0.3256 - accuracy: 0.8935 - val_loss: 0.2782 - val_accuracy: 0.9138 - 2s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "63/63 - 2s - loss: 0.1734 - accuracy: 0.9495 - val_loss: 0.2740 - val_accuracy: 0.9197 - 2s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "63/63 - 3s - loss: 0.1078 - accuracy: 0.9687 - val_loss: 0.3013 - val_accuracy: 0.9189 - 3s/epoch - 40ms/step\n",
      "Epoch 6/10\n",
      "63/63 - 2s - loss: 0.0884 - accuracy: 0.9752 - val_loss: 0.2956 - val_accuracy: 0.9220 - 2s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "63/63 - 3s - loss: 0.0635 - accuracy: 0.9816 - val_loss: 0.3241 - val_accuracy: 0.9202 - 3s/epoch - 40ms/step\n",
      "Epoch 8/10\n",
      "63/63 - 3s - loss: 0.0590 - accuracy: 0.9817 - val_loss: 0.3266 - val_accuracy: 0.9202 - 3s/epoch - 41ms/step\n",
      "Epoch 9/10\n",
      "63/63 - 3s - loss: 0.0527 - accuracy: 0.9825 - val_loss: 0.3400 - val_accuracy: 0.9207 - 3s/epoch - 40ms/step\n",
      "Epoch 10/10\n",
      "63/63 - 3s - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.3374 - val_accuracy: 0.9207 - 3s/epoch - 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28976fb33a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tfidf, ytrain,\n",
    "                              validation_data=(X_test_tfidf, ytest),\n",
    "                              epochs=10,\n",
    "                              batch_size=128,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648d8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "predicted = model.predict(X_test_tfidf)\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "680f9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = stop-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498e74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = predicted.shape[1]\n",
    "\n",
    "index = 0\n",
    "right = 0\n",
    "wrong = 0\n",
    "recalls = np.zeros([category+1,2])\n",
    "for i in predicted:\n",
    "    j=-1\n",
    "    \n",
    "    pred = np.argmax(i)\n",
    "    \n",
    "    if pred == int(ytest[index]):\n",
    "        recalls[pred][0]+=1\n",
    "        right +=1\n",
    "    else:\n",
    "        recalls[pred][1]+=1\n",
    "        wrong+=1\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43115db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = 0\n",
    "for row in recalls:\n",
    "    rec+=(row[0]/(row[0]+row[1])) \n",
    "rec = rec/(category+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14ecd6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3184112\n",
      "951\n",
      "0.9207367894649108\n",
      "0.9220385871071677\n"
     ]
    }
   ],
   "source": [
    "print(elapsed)\n",
    "print(wrong)\n",
    "print(right/(right+wrong))\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12792cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9220385871071677"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf2e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e81f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61baa9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37cb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e37086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf9606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
