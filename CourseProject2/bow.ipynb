{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d34c7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import glob\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19b59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : ['man', 'the', 'a', 'dog', 'there', 'was', 'had', 'and', 'walked']\n",
      "[[0. 1. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 2. 0. 1. 0. 0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "text = [\n",
    "  'There was a man',\n",
    "  'The man had a dog',\n",
    "  'The dog and the man walked',\n",
    "]\n",
    "# using tokenizer \n",
    "model = Tokenizer()\n",
    "model.fit_on_texts(text)\n",
    " \n",
    "#print keys \n",
    "print(f'Key : {list(model.word_index.keys())}')\n",
    " \n",
    "#create bag of words representation \n",
    "rep = model.texts_to_matrix(text, mode='count')\n",
    "print(rep)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06a18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='./20_newsgroups_Train'\n",
    "\n",
    "# root_dir needs a trailing slash (i.e. /root/dir/)\n",
    "i = 0\n",
    "test = []#pd.DataFrame(columns=['folder', 'fileName'])\n",
    "for filename in glob.iglob(root_dir + '**/**/*', recursive=True):\n",
    "    if i > 19:\n",
    "        for j, c in enumerate(filename[22:]):\n",
    "            if c.isdigit():\n",
    "                bs = j\n",
    "                #print(bs)\n",
    "                break\n",
    "        #print(filename[22:])\n",
    "        #print(filename[22:22+bs-1])#lable\n",
    "        label = filename[22:22+bs-1]\n",
    "        #print(filename[22+bs:])#filename\n",
    "        filenametmp = filename[22+bs:]\n",
    "        test.append([label,filenametmp])\n",
    "    #print(filename)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bcb2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocsAsStrings=[]\n",
    "allDocsAsStringsNoLabels = []\n",
    "for row in test:\n",
    "    fileToOpen= root_dir+'/'+row[0]+'/'+row[1]\n",
    "    #print(fileToOpen)\n",
    "    file=open(fileToOpen,\"r\")\n",
    "    tmp = file.read()\n",
    "    allDocsAsStrings.append([row[0],row[1],tmp])\n",
    "    allDocsAsStringsNoLabels.append(tmp)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c5844c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d0239f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\17193\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13032087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\17193\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a34b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stopWordsHit = []\n",
    "for doc in allDocsAsStringsNoLabels:\n",
    "    doc = doc.lower()\n",
    "    word_tokens = word_tokenize(doc)\n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "    filtered_sentence = []\n",
    "\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "        elif(w not in stopWordsHit):\n",
    "            stopWordsHit.append(w)\n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1e79f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in stopWordsHit:\n",
    "    fileToOpen=\"eliminate.txt\"\n",
    "    file=open(fileToOpen,\"a\")\n",
    "    file.write(word+'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62727430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., 'óáíïìåô', 'ýé', 'ÿhooked'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b2f19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english', lowercase=True)\n",
    "word_count = cv.fit_transform(allDocsAsStringsNoLabels) # Fit the model\n",
    "\n",
    "#print(cv.get_feature_names()) # Print all the words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d75b655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>0000000004</th>\n",
       "      <th>0000000005</th>\n",
       "      <th>0000001200</th>\n",
       "      <th>00000074</th>\n",
       "      <th>00000093</th>\n",
       "      <th>...</th>\n",
       "      <th>ée</th>\n",
       "      <th>égligent</th>\n",
       "      <th>élangea</th>\n",
       "      <th>érale</th>\n",
       "      <th>ête</th>\n",
       "      <th>íålittin</th>\n",
       "      <th>ðòïäáöá</th>\n",
       "      <th>óáíïìåô</th>\n",
       "      <th>ýé</th>\n",
       "      <th>ÿhooked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7999 rows × 116599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  0000  00000  00000000  0000000004  0000000005  0000001200  \\\n",
       "0      0    0     0      0         0           0           0           0   \n",
       "1      0    0     0      0         0           0           0           0   \n",
       "2      0    0     0      0         0           0           0           0   \n",
       "3      0    0     0      0         0           0           0           0   \n",
       "4      0    0     0      0         0           0           0           0   \n",
       "...   ..  ...   ...    ...       ...         ...         ...         ...   \n",
       "7994   0    0     0      0         0           0           0           0   \n",
       "7995   0    0     0      0         0           0           0           0   \n",
       "7996   0    0     0      0         0           0           0           0   \n",
       "7997   0    0     0      0         0           0           0           0   \n",
       "7998   0    0     0      0         0           0           0           0   \n",
       "\n",
       "      00000074  00000093  ...  ée  égligent  élangea  érale  ête  íålittin  \\\n",
       "0            0         0  ...   0         0        0      0    0         0   \n",
       "1            0         0  ...   0         0        0      0    0         0   \n",
       "2            0         0  ...   0         0        0      0    0         0   \n",
       "3            0         0  ...   0         0        0      0    0         0   \n",
       "4            0         0  ...   0         0        0      0    0         0   \n",
       "...        ...       ...  ...  ..       ...      ...    ...  ...       ...   \n",
       "7994         0         0  ...   0         0        0      0    0         0   \n",
       "7995         0         0  ...   0         0        0      0    0         0   \n",
       "7996         0         0  ...   0         0        0      0    0         0   \n",
       "7997         0         0  ...   0         0        0      0    0         0   \n",
       "7998         0         0  ...   0         0        0      0    0         0   \n",
       "\n",
       "      ðòïäáöá  óáíïìåô  ýé  ÿhooked  \n",
       "0           0        0   0        0  \n",
       "1           0        0   0        0  \n",
       "2           0        0   0        0  \n",
       "3           0        0   0        0  \n",
       "4           0        0   0        0  \n",
       "...       ...      ...  ..      ...  \n",
       "7994        0        0   0        0  \n",
       "7995        0        0   0        0  \n",
       "7996        0        0   0        0  \n",
       "7997        0        0   0        0  \n",
       "7998        0        0   0        0  \n",
       "\n",
       "[7999 rows x 116599 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.DataFrame(word_count.toarray(), columns = cv.get_feature_names())\n",
    "df_ # bag of words vectorized representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033daad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv('xgboost.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa86bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in allDocsAsStringsNoLabels:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(doc)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac5cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
